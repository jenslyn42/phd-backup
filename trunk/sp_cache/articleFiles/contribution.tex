\section{Challenges Of \spath Caching}\label{sec:competitors}

In this section we qualify the differences between static (no change in cache content at service runtime) and dynamic caching (Cache content is changed at service runtime) of \spathsns. We also introduce our state of the art competitor and explain why it is not an adequate solution for the \spath caching problem.


Using a dynamic cache\footnotemark and calculating the utility of each path is very expensive. If a dynamic cache is used, and we want to ensure it always keeps the most useful paths in the cache, it will be very expensive to calculate the utility of a new query with respect how much it overlaps with existing \spaths (i.e. how many vertices it shares with an existing \spathns) and how likely it will be able to answer a query in the future, thus adding a substantial overhead to query processing. As the utility of a \spath is so expensive to calculate, while the \spath service is running, it 
violates goal \ref{item:goal2} in section \ref{subsec:goals}.

Using \lru as the cache replacement policy in a dynamic cache ensures that only minimal overhead is added by using a dynamic cache. When a new query is submitted \lru evicts the least recently used \spath and keeps the most recently used \spaths in the cache.
\lru, however, has several shortcomings: 
\begin{itemize}
\item It has no way to determine the usefulness of inserting a path (i.e. no scoring function), which violates goal \ref{item:goal3} (Sec. \ref{subsec:goals}). Because \lru does not have a scoring function then, even if a path $SP$ is valuable (covers many potential queries), if a sequence of consecutive queries, which $SP$ can not cover, is submitted, then P will be evicted. 
\item \lru also does not have any way to optimize utilization of the cache space available, possibly wasting a lot of space. 
\item If no additional structure is added then querying the cache may require a scan of all paths in the cache to examine the cache can answer a query or not.
\item \lru does not consider utilization of the space in the cache.
\end{itemize}



\footnotetext{Every time a new query is submitted we consider evicting an old item from the cache and inserting the new query, using a replacement policy e.g. \lru}



To give an example of \lrus shortcomings we assume a cache of size 10 (i.e. has space for 10 vertices), using \lruns, and running on the map from figure \ref{fig:rxmap}. Queries Q1-Q6 from table \ref{tab:queries}, Q1 first and Q6 last.

The answer to Q1 and Q2 (table \ref{tab:queries}) are added to the cache as both results have a length of 5 and they can both fit. 

Q3 results in a cache hit with Q1. Q1 can answer Q3 because both start and target node (1 and 4) are on the cached path of Q1. This is a property is given by \oss (Lemma \ref{lem:oss}).

When Q4 is submitted Q2 will be evicted and Q4 inserted. Q2 will be evicted from the cache because no item in the cache can answer Q4, and Q2 is the least recently used.

Q5, which \textit{could} have been answered by Q2, now results in the eviction of Q1 and insertion of Q5 because the cache no longer contains any item able to answer Q5 and Q1 is now the least recently used item.

Q6 is not covered by Q3 or Q5, the current elements in the cache, resulting in a cache miss. Because there are 7 nodes in the cache and Q6:$\{v_3,v_4,v_5,v_6\}$ has 4 nodes, Q3 will be evicted (since it was inserted first) and Q6 inserted. 

The end result is that 30\% of the cache space is wasted and out of the 6 queries only we only resulted in a 1 cache hit. If Q1 and Q2 had been kept in the cache we could have had 3 cache hits. However, keeping Q1 and Q2 also  demonstrates \lrus problem with overlapping paths. Q1 and Q2 are identical except for one node, which waste a lot of space on duplicated nodes. Had we represented each node only once (addressed in section {subsec:cacherepresentatons}) we would be able to fit all nodes in the map in the cache.




% ---
% more beneficial to fill the cache offline and use a static cache, i.e. not evicting or inserting \spaths while the system is running.
% ----

% Intro to section; Why do we have baseline competitors, which ones will be introduced, and why those? 

% \lru is a competitor, but can not achieve good performance because:
% \begin{itemize}	
% 	\item Has no way to determine the usefulness of adding a path (i.e. no scoring function)
% 	\item Even if a path P is good (covers many queries), then if a sequence of consecutive queries comes which P can not cover, then it will be evicted.
% 	\item Has no way to optimize the number of paths in the cache, so available cache space may go unused.
% 	\item 
% \end{itemize}






\section{Contribution} \label{sec:contribution}

Intro to section \\
Show benefits of a static cache over a dynamic cache.\\
List all advantages of a static cache solution \\
(\textit{Static cache} solves goal 2. has zero maintenance cost after filling the cache.)

explain what will be introduced, which sub-problems are considered, and which subsections presents what.


\begin{table}
\begin{tabular*}{\columnwidth}{|l|p{0.76\columnwidth}|}
\hline
\bf Symbol		& \bf Meaning \\\hline
$Q_{s,t}$		& \spath query from $s$ to $t$ \\\hline
$\chi_{s,t}$		& The frequency of a (sub-)path \\\hline
$\Psi$ 			& The Cache \\\hline
$|SP|$			& Length of a \spath \\\hline
$|\Psi|$		& Number of vertices in the cache \\\hline
$\Phi(sp)$		& The set of all sub-paths in a \spath $sp$ \\\hline
$\Phi^c(\Psi)$		& The set of all unique (sub-)paths in $\Psi$ \\\hline
$\Gamma(\Psi)$		& Calculates the total utility of the content in the cache \\\hline 
$\mathbf{V}$ 		& The set of vertices in the Map \\\hline 
$G\mathbf{(V,E)}$ 	& Graph representation of the Map \\\hline 
\end{tabular*}
\caption{Table of Symbols}
\label{tab:symbols}
\end{table}


\begin{figure}[bht]
  \center
        \includegraphics[width=0.5\textwidth]{figures/fillcache}
        \caption{Insertion of cache elements in offline phase.}
  \label{fig:fillcache}
\end{figure}


\subsection{Benefit model}

We will define our goals more formally, introducing the benefit equations we aim to minimize.

A query is a pair of vertices ids $(v_s, v_t)$, denoted $Q_{s,t}$ and the \spath returned from such query we denote $SP_{s,t}$. 
In order to evaluate goal \ref{item:goal3} we calculate the utility of the content in the cache, denoted $\Gamma(\Psi)$. To calculate $\Gamma(\Psi)$ we find the set of unique sub-paths from all \spaths in the cache ($\Psi$) and sum up the frequency, $\chi_{s,t}$, of each unique path.
\textcolor{red}{$\chi$ Is a table and is computed from existing historical data. An example of different entries, $\chi_{s,t}$, is given in table \ref{tab:chi}}

In order to evaluate our method we try to maximize $\Gamma(\Psi)$ (Eq. \ref{eq:benefit}).


\begin{equation} \label{eq:upsi}
 \Phi^c(\Psi) = \bigcup\limits_{\forall \spath \in \Psi} \Phi(\spath)
\end{equation}

\begin{equation} \label{eq:benefit}
\Gamma(\Psi) = \sum\limits_{\forall SP_{s,t} \in \Phi^c(\Psi)} \chi_{s,t}
\end{equation}

\begin{equation} \label{eq:phi}
\Phi(sp) \leftarrow \{ SP_{s,t} | s \in sp, t \in sp, s \neq t\}
\end{equation}


\begin{table}
\begin{tabular}{l l p{0.78\columnwidth}}
Q1:	&	$Q_{1,6} =$ 	& $\{v_1,v_3,v_4,v_5,v_6\}$\\
Q2:	&	$Q_{2,6} =$ 	& $\{v_2,v_3,v_4,v_5,v_6\}$ \\
Q3:	&	$Q_{1,4} =$ 	& $\{v_1,v_3,v_4\}$ \\
Q4:	&	$Q_{4,7} =$ 	& $\{v_4,v_5,v_7\}$ \\
Q5:	&	$Q_{2,5} =$ 	& $\{v_2,v_3,v_4,v_5\}$ \\
Q6:	&	$Q_{3,6} =$ 	& $\{v_3,v_4,v_5,v_6\}$ \\
\end{tabular}
\caption{Example Queries}
\label{tab:queries}
\end{table}

\begin{table}
\begin{tabular}{r p{0.78\columnwidth}}
$\Phi(SP_{1,6})=$ 	& $\{SP_{1,3},SP_{1,4},SP_{1,5},SP_{1,6},SP_{3,4},SP_{3,5},$\\
		 	& $SP_{3,6},SP_{4,5},SP_{4,6},SP_{5,6}\}$ \\
$\Phi(SP_{2,6})=$ 	& $\{SP_{2,3},SP_{2,4},SP_{2,5},SP_{2,6},SP_{3,4},SP_{3,5},$ \\
			& $SP_{3,6},SP_{4,5},SP_{4,6},SP_{5,6}\}$ \\
$\Phi(SP_{1,4})=$ 	& $\{SP_{1,3},SP_{1,4},SP_{3,4}\}$ \\
$\Phi(SP_{4,7})=$ 	& $\{SP_{4,5},SP_{4,7},SP_{5,7}\}$ \\
$\Phi(SP_{2,5})=$ 	& $\{SP_{2,3},SP_{2,4},SP_{2,5},SP_{3,4},SP_{3,5},SP_{4,5}\}$ \\
$\Phi(SP_{3,6})=$ 	& $\{SP_{3,4},SP_{3,5},SP_{3,6},SP_{4,5},SP_{4,6},SP_{5,6}\}$ \\\hline
$\Phi^c(\Psi) =$ 	& $\{SP_{1,3},SP_{1,4},SP_{1,5},SP_{1,6},SP_{3,4},SP_{3,5},$ \\
			& $SP_{3,6},SP_{4,5},SP_{4,6},SP_{5,6},SP_{2,3},SP_{2,4},SP_{2,5},$ \\
			& $SP_{2,6},SP_{4,5},SP_{4,7},SP_{5,7}\}$  \\
\end{tabular}
\caption{$\Phi$ (Eq. \ref{eq:phi}) results for queries in table \ref{tab:queries}}
\label{tab:chi}
\end{table}

\begin{table}
\center
\begin{tabular}{|l||l|l|l|l|l|l|l|}
\textbf{$\chi$ ${^s/_t}$}& \textbf{1}	& \textbf{2}	& \textbf{3}	& \textbf{4}	& \textbf{5}	& \textbf{6}	& \textbf{7} \\\hline
\textbf{1}	& X	& -	& 4	& 2	& 3	& 1	& -	 \\
\textbf{2}	& -	& X	& 4	& 1	& 2	& 3	& -	 \\
\textbf{3}	& 4	& 4	& X	& 5	& 8	& 7	& -	 \\
\textbf{4}	& 2	& 1	& 5	& X	& 6	& 4	& 5	 \\
\textbf{5}	& 3	& 2	& 8	& 6	& X	& 2	& 4	 \\
\textbf{6}	& 1	& 3	& 7	& 4	& 2	& X	& -	 \\
\textbf{7}	& -	& -	& -	& 5	& 4	& -	& X	 \\
\end{tabular}
\caption{$\chi_{s,t}$ values for $\Phi^c(\Psi)$ in table \ref{tab:chi}}
\label{tab:freq}
\end{table}



When we want to evaluate the utility of $\Psi$ we first calculate $\Phi^c(\Psi)$ for each \spath. Table \ref{tab:chi} shows the set of sub-paths from the \spaths for each query Q1-Q6 from table \ref{tab:queries} (we assume all queries fit into the cache). Once we have all the sets of sub-paths from the cache content, we use equation \ref{eq:upsi} to union them together and obtain the set of unique sub-paths in the cache, $\Phi^c(\Psi)$ (see table \ref{tab:chi}). After we have obtained $U(\Psi)$, we use equation \ref{eq:benefit} to calculate $\Gamma(\Psi)$, the total benefit we expect to have with the content in $\Psi$. With the $\Phi^c(\Psi)$ obtained, using $\chi_{s,t}$ values from table \ref{tab:freq}, $\Gamma(\Psi)$ would be 62 ($4+3+5+7+4+4+2+1+4+2+1+8+6+2+1+3+5 = 62$).

When filling the cache, during the offline phase, potential \spath items are scored based the sum of $\chi_{s,t}$-values from sub-paths not already present in the cache. If we assume Q1 is already in the cache and we are considering to insert either Q2 or Q4 next, then we first find the sub-paths for each query result, which is not already present in the cache. For Q2 it is $\{SP_{2,3},SP_{2,4},SP_{2,5},SP_{2,6}\}$ and for Q4 $\{SP_{4,7},SP_{5,7}\}$. When using the values for $\chi_{s,t}$ from table \ref{tab:freq} the utility of Q2 is $4+1+2+3=10$ and for Q4 $5+4=9$. In this case we would then insert Q2 as it represents the largest expected if inserted.

\subsection{Hardness Analysis}
Theoretical analysis showing how hard the problem is to solve for \spath caching.\\
show it is NP-Hard
 

\subsection{Greedy algorithm}
The pseudo code describing our unoptimized greedy algorithm is presented here.


In algorithm \ref{alg:greedy}, line 1, we first initialize \textbf{H} as a max-heap. Line 2-3 fills \textbf{H} (utility,\spath) pairs, with utility calculated using equation \ref{eq:score}. 
Equation \ref{eq:score} calculates the score of a \spathns, $sp$, based on the sub-paths of $sp$ which are not already present in the cache (Eq. \ref{eq:usp}).


Line 4 of algorithm \ref{alg:greedy} starts looping to fill up the cache, terminating when either the cache is full (i.e. $| \Phi | \leq  \mathcal{B}$) or when the top (utility,\spath) has an utility value of 0




In line 6 we assign the pair (utility, \spath$_{s,t}$) with the highest utility to $\spath_{ms}$ and remove it from \textbf{H}.


Line 7-9 checks if the size of $\spath_{ms}$ is smaller or equal to the space available in the cache. If $\spath_{ms}$ is small enough, we insert it into the cache and recalculate the utility scores in \textbf{H}.


Assuming an empty cache, $\Phi_{size}=40$ (so all queries fit), and using data from table \ref{tab:chi} and  \ref{tab:freq}. We use the queries from table\ref{tab:queries}. Algorithm \ref{alg:greedy}  The utility of Q1-Q6 for 7 rounds (number of rounds Alg.. \ref{alg:greedy} need to consider Q1-Q6) is shown in table \ref{tab:steputil}. We will now explain round 1-7 in detail.


In the first round we calculate a score for all possible queries (Alg. \ref{alg:greedy}, line 4). Since the cache is empty, a \spath score consist of its frequency from table \ref{tab:freq}, as well as the frequency of its sub-paths. For Q1 this would give a utility of 4+2+3+1+5+8+7+6+4+2 = 42. The utility for Q2-Q6 is calculated in the same manner and only these example queries are shown for simplicity. From round 1 we can see that Q1 and Q2 are candidates for the first item in the cache. We choose Q1 here, how to break ties would depend on the individual max-heap implementation. 


In the second round (Alg. \ref{alg:greedy}, line 5-9) the cache is now no longer empty and all the scores has been recomputed (Alg. \ref{alg:greedy}, line 9). We can see the values have all gotten smaller and the value of Q1 now is $| \underline{\overline{01}}|$, this special value means it was nr. 1 to be added to the cache. The values have all gotten smaller since the valid sub-paths, for calculating the benefit of Q2-Q6, now does not include any sub-path which was in Q1. In round 2 Q4 now has the largest utility and will there for be added to the cache. As can be seen in round 3, then Q4 now has the special value $|\underline{\overline{02}}|$, indicating that it was the second item to be added to the cache.


Round three works as already seen in round 2, except Q2 does not get a lower utility score. This is possible because the \spath added to the cache in the previous round may not always share any edges with other \spaths in \textbf{H}. Q2 will be added in this step as it is the only remaining query with a positive score. The meaning of a zero score is that all the sub-paths in Q3,Q5,Q6 have all been covered by at least one \spath in the cache.

For round 4-7 All items are marked at being number four in the cache, this is because they all have a utility score of 4 and which one will be popped first from \textbf{H} will determined by the implementation of \textbf{H} and not our algorithm.


\begin{table}
\center
\begin{tabular}{| l| l| l| l| l|}\hline
$^{Round}/_{Query}$ 	& 1 	& 2 		& 3 	& 4 	\\\hline
Q1: ($Q_{1,6}$)		& $| \underline{\overline{42}}|$ 	& -	& -  	& - \\\hline
Q2: ($Q_{2,6}$)		& 42 	& 10	& $| \underline{\overline{10}} |$	& -\\\hline
Q3: ($Q_{1,4}$)		& 11	& 0	& 0	& 0	\\\hline
Q4: ($Q_{4,7}$)		& 15	& $| \underline{\overline{11}} |$	& -	& -  \\\hline
Q5: ($Q_{2,5}$)		& 26	& 7	& 0	& 0	\\\hline
Q6: ($Q_{3,6}$)		& 32	& 0	& 0	& 0	\\\hline
... & ... & ... & ... & ... \\\hline
\end{tabular}
\label{tab:steputil}
\caption{Utility for Q1-Q6 during 7 rounds of algorithm \ref{alg:greedy}. Boxed in values indicate the order of which items are added to the cache.}
\end{table}


\begin{equation} \label{eq:usp}
U_{sp} \leftarrow \Phi(SP_{s,t}) \setminus \Phi^c(\Psi)
\end{equation}

\begin{equation} \label{eq:score}
\{ (SP_{s,t}, \chi_{s,t}) | SP_{s,t} \in U_{sp}, s \neq t, (s,t) \in \chi \}
\end{equation}


\input{articleFiles/alg1}


\subsection{Statistics extraction}

%\input{articleFiles/alg2}
%use algorithm \ref{alg:score}


\subsubsection{Partition map} 
solves goal 1. reduce time on \spath calculation as it aids the cache with information on which paths may be useful.\\ 
discussion of kD-Tree.


\subsection{Cache representations and cache concepts} \label{subsec:cacherepresentatons}
How the cache is stored, and how we search it, is crucial to the performance of a cache. We will present the basic, naive, approach as well as 3 ideas for improvement.
% 
\subsubsection{Simple array of paths}% - baseline for goal 2, unoptimized and expensive to use.
The simplest way to represent a cache is a simple array of paths. This representation will we expensive to search since we may need to search all paths in the cache, akin to a double for loop, every time we want to check if an item is in the cache.

If we have a cache with $SP_{1,6},SP_{2,6},$ and $SP_{1,4}$ already in the cache and $Q_{4,7}$ is received, then we need to search the cache to see if we can get a cache hit. Since there can be no cache hit for $Q_{4,7}$ we need to scan all nodes for all paths, which would be 13 in this example (length of $SP_{1,6},SP_{2,6},$, $SP_{1,4}$, see table \ref{tab:queries}).

We will use this representation as the baseline for goal 2 when comparing the improvement when using any of the following cache representation ideas.

\subsubsection{Simple array of paths inverted list} - solves goal 2, reduces the query time of the cache.\\
A simple, yet very effective, way to improve the search time of a cache represented by a simple array is to add an inverted list on top of the cache. We add an inverted list with node ids as keys and values being a list of array indices which holds paths containing specific node ids. By using such an inverted list we just need to do the intersection between the lists retrieved by querying the inverted list with the start and target node ids. 


\textbf{*example*}

\subsubsection{Graph representation} - solves goal 1, allows for more paths in cache, which should translate more cache hits.

\subsubsection{Sharing sub-paths} - solves goal 1, allows for more paths in cache, translating to more cache hits. Unfortunately has a negative impact on goal 2 as it introduces some overhead in query time.

