\section{Introduction} \label{sec:intro}
%
%\subsection{Prepare for meeting}
%formulate problem
% why cache?
%\begin{itemize}
%\item less computational load
%\item faster response time
%\item better use of bandwidth \ref{sec:intro}
%\item
%\end{itemize}
%
%Describe strait forward solution
%
%just store query results in cache and only consider direct cache hit with a
%simple cache policy like LRU or even FIFO
%
%
%Come up with some simple solutions
%
%prepare:
%\begin{itemize}
%\item The definition and problem setting of shortest path caching
%\item Some simple methods
%\item Running examples to show how these methods work
%\item Identify advantages / disadvantages of these methods
%\end{itemize}


\section{Problem}

\subsection{Definitions and problem setting}
We assume a setting where owners of mobile, positioning enabled, devices want route planning assistance. We assume users prefer online route planning services over offline solutions. 
we expect users to use network enabled capable of determining and visualizing users location and route.
Users want fast response times from online services, comparable to using an offline application \cite{ref}
Using a cache reduces the computational burden \cite{ref} on an online service, providing faster end-user response time \cite{ref} by both freeing up computational resources to calculate new routes, as well as being able to immediately provide the shortest  path result from the cache.
We assume a scenario using only server side caching.


\subsection{methods}


\subsubsection{Baseline}\label{baselinemethod}
The strait forward baseline solution to implement a server side shortest path cache would be to store query results in the cache and only consider direct hits, and using a simple cache policy such as LRU or FIFO.
The advantage of this solution is clear: it is simple and easily implemented. 
This simplicity is however obviously also it's main disadvange, as it is too simple and very inefficient in terms of the utility the cache provides. Using items in the cache only when there is an exact match makes it exceedingly unlikely to get a cache hit due to the nature of route planning (many people share parts of routes, but few the same start and end points) and the sheer number of start-/end-point combinations possible. The 
%consider mentioning direct hit limitation.

\subsubsection{Baseline, improved}\label{baselinemethodimp}
One way to possible increase the utility of a naive cache as proposed in \ref{baselinemethod} would be to exploid the optimal substructure \cite{ref} property of the cache items.
There is a significant increase in cache hits to be expected by utilizing the optimal substracture of shortest path cache items since it is unlikely many people wil plan a route from/to the same place, but it is very likely that some sub-parts will be shared among users, and some users' full path laying within a longer path already calculated.
The disadvantage of doing this is the aditional computational resources required to examine the substructure of cached shortest path search results. It is currently not known if doing this is worth the efford, compaired to just calculating the route, possibly multiple times.


\subsubsection{Number 3}
Using the optimal substructure of each cache item it is possible to have much fewer items in cache and still retain a high cache hit percentage (assumption, need test result or proof), this percentage can further be improved by prefering longer paths in cache over shorter ones. A further improvement is to also prefer paths with sub-paths shared by many users.
By adding a more intuitive cache replacement policy which takes in to consideration both the usage of each cache item, as well as the coverage of previously often seen queries it is likely that the utility of the cache would be much higher.


\paragraph{\textbf{Number 3, ideas}}
use optimal substructure\\
prefer having longer paths in cache\\
prefer having paths with subpaths shared by many users\\
look at utility of cache items, not just usage when designing cache replacement policy.\\
\begin{itemize}
\item	prefer often used cache items
\item	prefer items which cover routes/areas often used in previous queries
\end{itemize}


%\paragraph{crap}
%We assume a setting where all users are equipped
%with a Mobile Device (MD) able to communicate and
%report the users position. All MDs are online and are
%continuesly reporting the users location at predetermined
%intervals. We use the terms user, mobile device, and
%client interchangeable and denote the set of MDs by
%UN. We expect a MD to be cabable of visualizing
%its current location.
%We assume a 2D scenario, where the movements of
%users uU are restricted to a road network G(V, E).
%V is the set of vertices, where each vertice v ‚àà V
%represents either a street intersection or an important
%landmark. E is the set of directed edges augmented
%by edge length and type. Edges are represented by
%a begin/end vertice pair and each edge represents the
%smallest unit of a road segment. e ‚àà E, each e being
%a tuple specifying id, start-/end-vertices, length, and
%Road Type (RT) (eid , vs , ve , elength , eRT ). RT is a
%hierarchy of the size/type of road i.e. highway, paved,
%or dirt road (Sec. 5.2).
%The simplest form of trajectory is a collection of tu-
%ples (time, longitude, latitude), ordered by the time
%attribute, but as we will work on a road network and
%in the spatio-temporal domain, such a basic notion of
%trajectories is not appropriate. We deÅne T as the set
%of trajectories, where each trajectory consist of an id
%(tid ), and a sequence of tuples containing an edge and



